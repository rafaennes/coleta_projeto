{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# MongoDB connection details\n",
    "#MONGO_URI = \"\" Colocar connection string\n",
    "DATABASE = \"gastospublicos\"\n",
    "COLLECTION_NAME = 'slv_notasfiscais'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'CNPJ EMITENTE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m collection \u001b[38;5;241m=\u001b[39m db[COLLECTION_NAME]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Extract relevant features for anomaly detection (ensuring a 2D array)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m data \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      7\u001b[0m     [\n\u001b[0;32m----> 8\u001b[0m         \u001b[38;5;28mint\u001b[39m(\u001b[43mdocument\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCNPJ EMITENTE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m),\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28mint\u001b[39m(document[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNPJ DESTINATÁRIO\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28mint\u001b[39m(document[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVALOR NOTA FISCAL\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     11\u001b[0m     ]\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m document \u001b[38;5;129;01min\u001b[39;00m collection\u001b[38;5;241m.\u001b[39mfind()\n\u001b[1;32m     13\u001b[0m ]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Convert data to a NumPy array for better shape handling\u001b[39;00m\n\u001b[1;32m     16\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CNPJ EMITENTE'"
     ]
    }
   ],
   "source": [
    "client = pymongo.MongoClient(MONGO_URI)\n",
    "db = client[DATABASE]\n",
    "collection = db[COLLECTION_NAME]\n",
    "\n",
    "# Extract relevant features for anomaly detection (ensuring a 2D array)\n",
    "data = [\n",
    "    [\n",
    "        int(document[\"CNPJ EMITENTE\"]),\n",
    "        int(document[\"CNPJ DESTINATÁRIO\"]),\n",
    "        int(document[\"VALOR NOTA FISCAL\"])\n",
    "    ]\n",
    "    for document in collection.find()\n",
    "]\n",
    "\n",
    "# Convert data to a NumPy array for better shape handling\n",
    "data = np.array(data)\n",
    "\n",
    "# Debugging: Print shape and data type\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"Data: {data[:5]}\")  # Print first 5 entries to verify the content\n",
    "\n",
    "# Ensure data is in 2D array\n",
    "if len(data.shape) == 1:\n",
    "    data = data.reshape(-1, 3)\n",
    "\n",
    "# Debugging: Print the reshaped data\n",
    "print(f\"Reshaped Data shape: {data.shape}\")\n",
    "\n",
    "# Train the Isolation Forest model\n",
    "model = IsolationForest(contamination=\"auto\")  # Adjust contamination as needed\n",
    "model.fit(data)\n",
    "\n",
    "# Predict anomaly scores\n",
    "anomaly_scores = model.decision_function(data)\n",
    "\n",
    "# Identify anomalies based on a threshold\n",
    "threshold = 0  # Adjust threshold as needed\n",
    "anomalies = [i for i, score in enumerate(anomaly_scores) if score < threshold]\n",
    "\n",
    "# Print the anomalous documents\n",
    "print(\"Anomalous documents:\")\n",
    "for index in anomalies:\n",
    "    document = collection.find().skip(index).limit(1)[0]  # Retrieve the document at the specific index\n",
    "    print(document)\n",
    "\n",
    "# Close the MongoDB connection\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "client = pymongo.MongoClient(MONGO_URI)\n",
    "db = client[DATABASE]\n",
    "collection = db[COLLECTION_NAME]\n",
    "\n",
    "features = [\"VALOR NOTA FISCAL\", # Replace/add features as needed.\n",
    "            'CPF/CNPJ Emitente',\n",
    "            'UF EMITENTE',\n",
    "            'CNPJ DESTINATÁRIO',\n",
    "            'DATA/HORA EVENTO MAIS RECENTE',\n",
    "            'UF DESTINATÁRIO'\n",
    "           ]\n",
    "data_from_mongo = collection.find({}, {feature: 1 for feature in features}) # Project only the required features\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(list(data_from_mongo))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Preprocessing and Feature Engineering (Same as before):\n",
    "\n",
    "# Select relevant numeric features\n",
    "numeric_features = ['VALOR NOTA FISCAL', # List your numeric features\n",
    "                    ]\n",
    "\n",
    "data = df[numeric_features].copy()\n",
    "\n",
    "# Handle missing values (if any)\n",
    "data.fillna(data.mean(), inplace=True)  # Or use another strategy\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# 3. Isolation Forest Model (Same as before):\n",
    "\n",
    "model = IsolationForest(n_estimators=100, contamination='auto', random_state=42)\n",
    "model.fit(scaled_data)\n",
    "\n",
    "\n",
    "# 4. Add Anomaly Scores and Predictions back to the DataFrame:\n",
    "\n",
    "df['anomaly_score'] = model.decision_function(scaled_data)\n",
    "df['anomaly'] = model.predict(scaled_data)\n",
    "\n",
    "\n",
    "\n",
    "# 5.  Analysis and Investigation (Similar as before, but with MongoDB integration):\n",
    "\n",
    "anomalies = df[df['anomaly'] == -1]\n",
    "\n",
    "# ... (Analysis as before: grouping, analyzing distributions, etc.)\n",
    "\n",
    "\n",
    "# Example: Update the MongoDB collection with anomaly flags:\n",
    "\n",
    "#for index, row in anomalies.iterrows():\n",
    " #   collection.update_one({'_id': row['_id']}, {'$set': {'anomaly': True}}) # Mark as anomaly in MongoDB\n",
    "\n",
    "# Or store anomaly results in a separate collection\n",
    "\n",
    "\n",
    "# 6. Refinement and Iteration:  (As before)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
